# MachineLearningForNLP
Tokenization: 
Text Preprocessing Tokenization : simple process converting paragraph into sentence. further sentence --> words--> character depending on case
Terminologies: Corpus ---> paragraph Vocabulary ---> unique words Documents -----> Sentences
